{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_df = pd.read_csv('../data/summaries_train.csv')\n",
    "prompts_df = pd.read_csv('../data/prompts_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = summaries_df.merge(prompts_df, on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(row):\n",
    "    resumen_estudiante = row['text']\n",
    "    texto_original = row['prompt_text']\n",
    "    \n",
    "    scores = scorer.score(texto_original, resumen_estudiante)\n",
    "    return {\n",
    "        'rouge1_recall': scores['rouge1'].recall,\n",
    "        'rouge1_precision': scores['rouge1'].precision,\n",
    "        'rouge1_f1': scores['rouge1'].fmeasure,\n",
    "        'rouge2_recall': scores['rouge2'].recall,\n",
    "        'rouge2_precision': scores['rouge2'].precision,\n",
    "        'rouge2_f1': scores['rouge2'].fmeasure,\n",
    "        'rougeL_recall': scores['rougeL'].recall,\n",
    "        'rougeL_precision': scores['rougeL'].precision,\n",
    "        'rougeL_f1': scores['rougeL'].fmeasure\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = df_merged.apply(calculate_rouge_scores, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_merged, rouge_scores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "df_merged.to_csv('../results/rouge_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('../results/rouge_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparable_cols = ['content', 'wording', 'rouge1_recall', 'rouge1_precision', 'rouge1_f1', \n",
    "                    'rouge2_recall', 'rouge2_precision', 'rouge2_f1', \n",
    "                    'rougeL_recall', 'rougeL_precision', 'rougeL_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_merged[comparable_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_corr = corr_matrix.loc[['content', 'wording'], ['rouge1_recall', 'rouge1_precision', 'rouge1_f1', \n",
    "                                                                         'rouge2_recall', 'rouge2_precision', 'rouge2_f1', \n",
    "                                                                         'rougeL_recall', 'rougeL_precision', 'rougeL_f1']]\n",
    "\n",
    "# add a column with the name of the metric\n",
    "score_corr['metric'] = score_corr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "score_corr.to_csv('../results/rouge_scores_corr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
